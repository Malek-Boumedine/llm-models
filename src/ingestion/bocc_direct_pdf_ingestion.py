import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))
from src.utils import load_pdf_files, chunk_and_insert_pdf_file, log_and_print, get_juridical_separators

from chromadb.utils import embedding_functions as ef
from dotenv import load_dotenv
from src.db.connection import get_qdrant_client, create_collection_qdrant, disable_indexing, reactivate_indexing
from datetime import datetime
import re
from typing import Dict, Optional, List
from src.utils import get_embedding_function_with_fallback

# ==============================================================================================================

os.environ["CHROMA_ENABLE_TELEMETRY"] = "False"
load_dotenv()

client_host = os.getenv("QDRANT_HOST", "http://localhost:6333")
files_path = os.path.join("data/BOCC_pdf_direct_link")


# ==============================================================================================================

def extract_bocc_metadata_expert(file_name: str) -> Dict[str, Optional[str]]:
    """
    Extracteur expert de m√©tadonn√©es pour les bulletins officiels BOCC
    Patterns optimis√©s pour une extraction fiable
    """
    metadata = {
        "bulletin_number": None,
        "bulletin_date": None,
        "bulletin_year": None,
        "bulletin_type": "BOCC_direct_pdf"
    }
    
    # Patterns robustes pour extraction bulletin
    bulletin_patterns = [
        r'n¬∞\s*(\d{4}[_\-]\d+)',  # Format principal: n¬∞ 2024_15
        r'n¬∞\s*(\d{4}[_\-]\d{1,3})',  # Variations avec 1-3 chiffres
        r'numero\s*(\d{4}[_\-]\d+)',  # Alternative "numero"
        r'bulletin\s*(\d{4}[_\-]\d+)'  # Alternative "bulletin"
    ]
    
    # Patterns robustes pour extraction date
    date_patterns = [
        r'du\s*(\d{1,2}[_\-]\d{1,2}[_\-]\d{4})',  # Format principal: du 15_01_2024
        r'date\s*(\d{1,2}[_\-]\d{1,2}[_\-]\d{4})',  # Alternative "date"
        r'(\d{1,2}[_\-]\d{1,2}[_\-]\d{4})'  # Date seule
    ]
    
    # Extraction du num√©ro de bulletin
    for pattern in bulletin_patterns:
        match = re.search(pattern, file_name, re.IGNORECASE)
        if match:
            bulletin_number = match.group(1)
            metadata["bulletin_number"] = bulletin_number
            # Extraire l'ann√©e du bulletin
            year_match = re.search(r'(\d{4})', bulletin_number)
            if year_match:
                metadata["bulletin_year"] = year_match.group(1)
            break
    
    # Extraction de la date
    for pattern in date_patterns:
        match = re.search(pattern, file_name, re.IGNORECASE)
        if match:
            date_str = match.group(1)
            try:
                # Normaliser les s√©parateurs
                date_normalized = re.sub(r'[_\-]', '_', date_str)
                # Essayer diff√©rents formats
                date_formats = ["%d_%m_%Y", "%d_%m_%y", "%Y_%m_%d"]
                
                for fmt in date_formats:
                    try:
                        parsed_date = datetime.strptime(date_normalized, fmt)
                        metadata["bulletin_date"] = parsed_date
                        if not metadata["bulletin_year"]:
                            metadata["bulletin_year"] = str(parsed_date.year)
                        break
                    except ValueError:
                        continue
                        
                if metadata["bulletin_date"]:
                    break
                    
            except Exception as e:
                print(f"Erreur parsing date {date_str}: {e}")
                continue
    
    return metadata

def get_bocc_specific_separators() -> List[str]:
    """
    Separators sp√©cifiquement optimis√©s pour les bulletins officiels
    """
    base_separators = get_juridical_separators()
    
    # Separators sp√©cifiques aux bulletins officiels
    bocc_separators = [
        # Structures sp√©cifiques BOCC
        "\n\nARR√äT√â du ",
        "\n\nARR√äT√â DU ",
        "\n\nD√âCRET n¬∞ ",
        "\n\nD√âCRET N¬∞ ",
        "\n\nCIRCULAIRE du ",
        "\n\nCIRCULAIRE DU ",
        "\n\nINSTRUCTION du ",
        "\n\nAVIS ",
        "\n\nCOMMUNICATION ",
        
        # Extensions sp√©cifiques
        "\n\nEXTENSION ",
        "\n\nELARGISSEMENT ",
        "\n\nAGR√âMENT ",
        "\n\nD√âNONCIATION ",
        
        # Structures d'articles dans les bulletins
        "\n\nLe pr√©sent arr√™t√© ",
        "\n\nLa pr√©sente d√©cision ",
        "\n\nLe pr√©sent accord ",
        
        # Num√©rotation sp√©cifique
        "\n\n1¬∞ ",
        "\n\n2¬∞ ",
        "\n\n3¬∞ ",
        "\n\n- ",
        
    ] + base_separators
    
    return bocc_separators

def validate_bocc_content(text: str) -> bool:
    """
    Validation simplifi√©e du contenu BOCC - Filtre seulement le bruit √©vident
    """
    if not text or len(text.strip()) < 40:
        return False
    
    # Filtre seulement le bruit √©vident
    noise_indicators = [
        r'^\s*\d+\s*$',  # Pages contenant seulement un num√©ro
        r'^\s*sommaire\s*$',  # Pages sommaire
        r'^\s*index\s*$',  # Pages index
        r'^\s*page\s*\d+\s*$',  # Page X
        r'^\s*imprimer\s*$',  # Bouton imprimer
        r'^\s*t[e√©]l[e√©]charger\s*$',  # Bouton t√©l√©charger
    ]
    
    text_lower = text.lower().strip()
    for noise in noise_indicators:
        if re.match(noise, text_lower):
            return False
    
    return True  # ‚úÖ Accepte tout le reste

def preprocess_bocc_text(text: str) -> str:
    """
    Preprocessing sp√©cifique pour les bulletins officiels
    """
    if not text:
        return ""
    
    # Nettoyage de base
    from src.utils import clean_juridical_text
    text = clean_juridical_text(text)
    
    # Corrections sp√©cifiques aux bulletins officiels
    
    # Standardiser les r√©f√©rences l√©gales
    text = re.sub(r'(?i)code\s+du\s+travail\s*[,\s]*article\s*([A-Z]?\d+(?:\-\d+)*)', 
                  r'Code du travail, article \1', text)
    
    # Standardiser les dates dans le texte
    text = re.sub(r'(?i)arr[e√™]t[e√©]\s+du\s+(\d{1,2})\s+(\w+)\s+(\d{4})', 
                  r'Arr√™t√© du \1 \2 \3', text)
    
    # Standardiser les r√©f√©rences aux conventions
    text = re.sub(r'(?i)convention\s+collective\s+nationale\s+(?:du\s+)?(\d{1,2})\s+(\w+)\s+(\d{4})', 
                  r'Convention collective nationale du \1 \2 \3', text)
    
    # Corriger la num√©rotation des articles
    text = re.sub(r'(?i)art\.\s*([A-Z]?\d+(?:\-\d+)*)', r'Article \1', text)
    text = re.sub(r'(?i)art\s+([A-Z]?\d+(?:\-\d+)*)', r'Article \1', text)
    
    # Standardiser les codes IDCC
    text = re.sub(r'(?i)idcc\s*[:\-]?\s*n?\s*(\d+)', r'IDCC \1', text)
    
    return text

def ingest_direct_pdf_bocc(pdf_path: str = files_path, client_host: str = client_host) -> int:
    """
    Ingestion expert des bulletins officiels avec extraction de m√©tadonn√©es optimis√©e
    """
    collection_name = "bocc"
    separators = get_bocc_specific_separators()
    
    # Configuration chunks optimis√©e pour BOCC
    chunk_size = 1200  # Plus grand pour capturer les articles complets
    chunk_overlap = 300  # Plus de chevauchement pour la coh√©rence juridique
    
    logs_dir = "logs/bocc_logs/direct_pdf/"
    os.makedirs(logs_dir, exist_ok=True)
    now_str = datetime.now().strftime("%d-%m-%Y_%H-%M")
    logfile_path = f"{logs_dir}log_{now_str}.log"
    
    with open(logfile_path, "w", encoding="utf-8") as logfile:
        log_and_print("=" * 80, logfile)
        log_and_print("INGESTION EXPERT BOCC - LIENS DIRECTS PDF", logfile)
        log_and_print("=" * 80, logfile)
        
        # Chargement des fichiers PDF
        try:
            pdf_documents = load_pdf_files(pdf_path)
            if pdf_documents:
                log_and_print(f"‚úì {len(pdf_documents)} fichiers PDF charg√©s avec succ√®s", logfile)
            else:
                log_and_print(f"‚úó Aucun fichier PDF trouv√© dans {pdf_path}", logfile)
                return 0
        except Exception as e:
            log_and_print(f"‚úó Erreur chargement fichiers: {e}", logfile)
            return 0
        
        # Configuration embedding
        try:
            embedding_function, active_model = get_embedding_function_with_fallback(logfile)
            log_and_print(f"‚úì Mod√®le embedding actif: {active_model}", logfile)
        except Exception as e:
            log_and_print(f"‚úó Impossible de charger les mod√®les d'embedding: {e}", logfile)
            return 0
                
        # Connexion base de donn√©es
        try:
            client = get_qdrant_client(client_host, logfile=logfile)
            create_collection_qdrant(client=client, collection_name=collection_name, 
                            embedding_function=embedding_function, logfile=logfile)
            disable_indexing(client=client, collection_name=collection_name, logfile=logfile)
            log_and_print(f"‚úì Collection '{collection_name}' configur√©e", logfile)
        except Exception as e:
            log_and_print(f"‚úó Erreur configuration DB: {e}", logfile)
            return 0
        
        # Traitement des fichiers
        success_count = 0
        error_count = 0
        
        try:
            for i, file_path in enumerate(pdf_documents, 1):
                file_name = os.path.splitext(os.path.basename(file_path))[0]
                
                log_and_print(f"\n{'='*60}", logfile)
                log_and_print(f"TRAITEMENT {i}/{len(pdf_documents)}: {file_name}", logfile)
                log_and_print(f"{'='*60}", logfile)
                
                # Extraction des m√©tadonn√©es avec l'extracteur expert
                metadata = extract_bocc_metadata_expert(file_name)
                
                # Log des m√©tadonn√©es extraites
                log_and_print(f"üìä M√©tadonn√©es extraites:", logfile)
                for key, value in metadata.items():
                    if value:
                        log_and_print(f"  ‚Ä¢ {key}: {value}", logfile)
                
                # Validation des m√©tadonn√©es critiques
                if not metadata["bulletin_number"] and not metadata["bulletin_date"]:
                    log_and_print(f"‚ö†Ô∏è  Aucune m√©tadonn√©e critique extraite pour {file_name}", logfile)
                
                # Traitement du fichier avec m√©tadonn√©es
                try:
                    result = chunk_and_insert_pdf_file(
                        client=client,
                        collection=collection_name,
                        embedding_function=embedding_function,
                        file_path=file_path,
                        extra_metadata=metadata,  # üî• FIX CRITIQUE: Passage des m√©tadonn√©es
                        separators=separators,
                        chunk_size=chunk_size,
                        chunk_overlap=chunk_overlap
                    )
                    
                    if result:
                        success_count += 1
                        log_and_print(f"‚úÖ {file_name} trait√© avec succ√®s", logfile)
                    else:
                        error_count += 1
                        log_and_print(f"‚ùå √âchec traitement {file_name}", logfile)
                        
                except Exception as e:
                    error_count += 1
                    log_and_print(f"‚ùå Erreur traitement {file_name}: {e}", logfile)
            
            # R√©activation de l'indexation
            reactivate_indexing(client=client, collection_name=collection_name, logfile=logfile)
            
            # Rapport final
            log_and_print(f"\n{'='*60}", logfile)
            log_and_print(f"RAPPORT FINAL", logfile)
            log_and_print(f"{'='*60}", logfile)
            log_and_print(f"‚úÖ Fichiers trait√©s avec succ√®s: {success_count}", logfile)
            log_and_print(f"‚ùå Fichiers en erreur: {error_count}", logfile)
            log_and_print(f"üìä Taux de succ√®s: {success_count/(success_count+error_count)*100:.1f}%", logfile)
            
            if success_count > 0:
                # Compter le total de chunks r√©ellement ins√©r√©s
                try:
                    collection_info = client.get_collection(collection_name)
                    total_chunks = getattr(collection_info, 'points_count', 0)
                    log_and_print(f"üìä Total chunks dans la collection: {total_chunks}", logfile)
                    return total_chunks
                except:
                    return success_count
            else:
                return 0
            
        except Exception as e:
            log_and_print(f"‚ùå Erreur critique durant le traitement: {e}", logfile)
            return 0

# ==============================================================================================================

if __name__ == "__main__":
    result = ingest_direct_pdf_bocc()
    if result:
        print("üéâ Ingestion BOCC direct PDF termin√©e avec succ√®s!")
    else:
        print("üí• √âchec de l'ingestion BOCC direct PDF")
