import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))
from src.utils import load_pdf_files, chunk_and_insert_pdf_file, log_and_print, get_juridical_separators

from chromadb.utils import embedding_functions as ef
from dotenv import load_dotenv
from src.db.connection import get_qdrant_client, create_collection, disable_indexing, reactivate_indexing
from datetime import datetime
import re
from typing import Dict, Optional, List
from src.utils import get_embedding_function_with_fallback


# ==============================================================================================================

os.environ["CHROMA_ENABLE_TELEMETRY"] = "False"
load_dotenv()

client_host = os.getenv("QDRANT_HOST", "http://localhost:6333")
embedding_model = os.getenv("OLLAMA_EMBEDDING_MODEL", "paraphrase-multilingual:278m-mpnet-base-v2-fp16")
files_path = os.path.join("../1.scraping_data/data/BOCC_no_pdf_direct_link/")

# ==============================================================================================================

def extract_bocc_no_direct_metadata_expert(file_name: str) -> Dict[str, Optional[str]]:
    """
    Extracteur expert de mÃ©tadonnÃ©es pour les bulletins officiels BOCC sans lien direct
    Patterns adaptÃ©s pour ce type de fichier spÃ©cifique
    """
    metadata = {
        "bulletin_number": None,
        "bulletin_date": None,
        "bulletin_year": None,
        "bulletin_type": "BOCC_no_direct_pdf",
        "source_type": "bulletin_scraped"
    }
    
    # Patterns spÃ©cifiques pour les fichiers sans lien direct
    # Ces fichiers peuvent avoir des noms diffÃ©rents aprÃ¨s scraping
    bulletin_patterns = [
        r'nÂ°\s*(\d{4}[_\-]\d+)',  # Format standard
        r'bulletin[_\-](\d{4})[_\-](\d+)',  # Format alternatif
        r'bocc[_\-](\d{4})[_\-](\d+)',  # Format BOCC
        r'(\d{4})[_\-](\d{1,3})',  # Format simplifiÃ© annÃ©e-numÃ©ro
        r'num[eÃ©]ro[_\s]*(\d{4}[_\-]\d+)'  # Variations "numÃ©ro"
    ]
    
    # Patterns pour dates avec plus de variabilitÃ©
    date_patterns = [
        r'du\s*(\d{1,2})[_\-](\d{1,2})[_\-](\d{4})',  # Format: du 15_01_2024
        r'date[_\-](\d{1,2})[_\-](\d{1,2})[_\-](\d{4})',  # Format: date_15_01_2024
        r'(\d{1,2})[_\-](\d{1,2})[_\-](\d{4})',  # Format: 15_01_2024
        r'(\d{4})[_\-](\d{1,2})[_\-](\d{1,2})',  # Format: 2024_01_15
        r'(\d{8})',  # Format: 20240115
    ]
    
    # Extraction du numÃ©ro de bulletin
    for pattern in bulletin_patterns:
        match = re.search(pattern, file_name, re.IGNORECASE)
        if match:
            if len(match.groups()) == 1:
                bulletin_number = match.group(1)
            else:
                # Cas oÃ¹ on a annÃ©e et numÃ©ro sÃ©parÃ©s
                bulletin_number = f"{match.group(1)}_{match.group(2)}"
            
            metadata["bulletin_number"] = bulletin_number
            
            # Extraire l'annÃ©e
            year_match = re.search(r'(\d{4})', bulletin_number)
            if year_match:
                metadata["bulletin_year"] = year_match.group(1)
            break
    
    # Extraction de la date avec gestion des formats multiples
    for pattern in date_patterns:
        match = re.search(pattern, file_name, re.IGNORECASE)
        if match:
            try:
                if len(match.groups()) == 1:
                    # Format YYYYMMDD
                    date_str = match.group(1)
                    if len(date_str) == 8:
                        parsed_date = datetime.strptime(date_str, "%Y%m%d")
                        metadata["bulletin_date"] = parsed_date
                        metadata["bulletin_year"] = str(parsed_date.year)
                        break
                        
                elif len(match.groups()) == 3:
                    # Format avec jour, mois, annÃ©e
                    day, month, year = match.groups()
                    
                    # Essayer diffÃ©rents ordres
                    date_combinations = [
                        (day, month, year),     # DD/MM/YYYY
                        (year, month, day),     # YYYY/MM/DD
                        (month, day, year),     # MM/DD/YYYY
                    ]
                    
                    for d, m, y in date_combinations:
                        try:
                            parsed_date = datetime(int(y), int(m), int(d))
                            metadata["bulletin_date"] = parsed_date
                            metadata["bulletin_year"] = str(parsed_date.year)
                            break
                        except ValueError:
                            continue
                    
                    if metadata["bulletin_date"]:
                        break
                        
            except Exception as e:
                print(f"Erreur parsing date dans {file_name}: {e}")
                continue
    
    return metadata

def get_bocc_no_direct_separators() -> List[str]:
    """
    Separators optimisÃ©s pour les bulletins BOCC sans lien direct
    Ces fichiers peuvent avoir une structure lÃ©gÃ¨rement diffÃ©rente
    """
    base_separators = get_juridical_separators()
    
    # Separators spÃ©cifiques aux bulletins scrapÃ©s
    bocc_no_direct_separators = [
        # Structures typiques aprÃ¨s scraping
        "\n\nTexte nÂ° ",
        "\n\nTexte numÃ©ro ",
        "\n\nDocument nÂ° ",
        "\n\nDocument numÃ©ro ",
        
        # Structures administratives
        "\n\nARRÃŠTÃ‰ du ",
        "\n\nARRÃŠTÃ‰ DU ",
        "\n\nDÃ‰CRET nÂ° ",
        "\n\nDÃ‰CRET NÂ° ",
        "\n\nCIRCULAIRE ",
        "\n\nINSTRUCTION ",
        "\n\nAVIS ",
        "\n\nDÃ‰CISION ",
        "\n\nCOMMUNICATION ",
        
        # Structures d'extension
        "\n\nEXTENSION d'accord ",
        "\n\nEXTENSION de la convention ",
        "\n\nELARGISSEMENT ",
        "\n\nAGRÃ‰MENT ",
        "\n\nDÃ‰NONCIATION ",
        
        # Marqueurs de dÃ©but/fin typiques
        "\n\nMinistÃ¨re ",
        "\n\nDirection ",
        "\n\nService ",
        "\n\nBureau ",
        
        # Separators de contenu
        "\n\nVu ",
        "\n\nConsidÃ©rant ",
        "\n\nArrÃªte ",
        "\n\nDÃ©cide ",
        
    ] + base_separators
    
    return bocc_no_direct_separators

def validate_bocc_no_direct_content(text: str) -> bool:
    """
    Validation spÃ©cifique du contenu BOCC sans lien direct
    """
    if not text or len(text.strip()) < 30:
        return False
    
    # Indicateurs spÃ©cifiques aux bulletins scrapÃ©s
    bocc_indicators = [
        r'convention\s+collective',
        r'bulletin\s+officiel',
        r'arr[eÃª]t[eÃ©]',
        r'd[eÃ©]cret',
        r'circulaire',
        r'extension',
        r'[eÃ©]largissement',
        r'agr[eÃ©]ment',
        r'd[eÃ©]nonciation',
        r'code\s+du\s+travail',
        r'minist[eÃ¨]re',
        r'direction\s+g[eÃ©]n[eÃ©]rale',
        r'idcc',
        r'classification',
        r'salaire',
        r'dur[eÃ©]e\s+du\s+travail',
        r'formation\s+professionnelle',
        r'protection\s+sociale'
    ]
    
    text_lower = text.lower()
    indicator_count = 0
    
    for indicator in bocc_indicators:
        if re.search(indicator, text_lower):
            indicator_count += 1
    
    # NÃ©cessite au moins 2 indicateurs pour validation
    return indicator_count >= 2

def preprocess_bocc_no_direct_text(text: str) -> str:
    """
    Preprocessing spÃ©cifique pour les bulletins sans lien direct
    """
    if not text:
        return ""
    
    # Nettoyage de base
    from src.utils import clean_juridical_text
    text = clean_juridical_text(text)
    
    # Corrections spÃ©cifiques aux bulletins scrapÃ©s
    
    # Nettoyer les artefacts de scraping
    text = re.sub(r'(?i)page\s+\d+\s+sur\s+\d+', '', text)
    text = re.sub(r'(?i)imprimer\s+cette\s+page', '', text)
    text = re.sub(r'(?i)retour\s+au\s+sommaire', '', text)
    text = re.sub(r'(?i)t[eÃ©]l[eÃ©]charger\s+le\s+pdf', '', text)
    
    # Standardiser les rÃ©fÃ©rences administratives
    text = re.sub(r"(?i)minist[eÃ¨]re\s+du\s+travail,?\s+de\s+l['â€™]?emploi", 
              "MinistÃ¨re du Travail, de l'Emploi", text)    
    
    # Standardiser les rÃ©fÃ©rences de direction
    text = re.sub(r'(?i)direction\s+g[eÃ©]n[eÃ©]rale\s+du\s+travail', 
                  'Direction gÃ©nÃ©rale du travail', text)
    
    # Standardiser les structures d'arrÃªtÃ©
    text = re.sub(r'(?i)arr[eÃª]t[eÃ©]\s+du\s+(\d{1,2})\s+(\w+)\s+(\d{4})', 
                  r'ArrÃªtÃ© du \1 \2 \3', text)
    
    # Standardiser les rÃ©fÃ©rences aux textes
    text = re.sub(r'(?i)vu\s+le\s+code\s+du\s+travail', 'Vu le Code du travail', text)
    text = re.sub(r'(?i)vu\s+la\s+loi\s+nÂ°\s*([0-9\-]+)', r'Vu la loi nÂ° \1', text)
    
    # Corriger les numÃ©rotations
    text = re.sub(r'(?i)article\s+([A-Z]?\d+(?:[.\-]\d+)*)', r'Article \1', text)
    
    return text

def ingest_no_direct_pdf_bocc(pdf_path: str = files_path, client_host: str = client_host) -> int:
    """
    Ingestion expert des bulletins officiels BOCC sans lien direct PDF
    """
    collection_name = "bocc"
    separators = get_bocc_no_direct_separators()
    
    # Configuration chunks adaptÃ©e pour les bulletins scrapÃ©s
    chunk_size = 1400  # LÃ©gÃ¨rement plus petit pour les textes scrapÃ©s
    chunk_overlap = 220  # Plus de chevauchement pour compenser la fragmentation
    
    logs_dir = "logs/bocc_logs/no_direct_pdf/"
    os.makedirs(logs_dir, exist_ok=True)
    now_str = datetime.now().strftime("%d-%m-%Y_%H-%M")
    logfile_path = f"{logs_dir}log_{now_str}.log"
    
    with open(logfile_path, "w", encoding="utf-8") as logfile_handle:
        log_and_print("=" * 80, logfile_handle)
        log_and_print("INGESTION EXPERT BOCC - SANS LIEN DIRECT PDF", logfile_handle)
        log_and_print("=" * 80, logfile_handle)
        
        # Chargement des fichiers PDF
        try:
            pdf_documents = load_pdf_files(pdf_path)
            if pdf_documents:
                log_and_print(f"âœ“ {len(pdf_documents)} fichiers PDF chargÃ©s avec succÃ¨s", logfile_handle)
            else:
                log_and_print(f"âœ— Aucun fichier PDF trouvÃ© dans {pdf_path}", logfile_handle)
                return 0
        except Exception as e:
            log_and_print(f"âœ— Erreur chargement fichiers: {e}", logfile_handle)
            return 0
        
        # Configuration embedding
        try:
            embedding_function, active_model = get_embedding_function_with_fallback(logfile_handle)
            log_and_print(f"âœ“ ModÃ¨le embedding actif: {active_model}", logfile_handle)
        except Exception as e:
            log_and_print(f"âœ— Impossible de charger les modÃ¨les d'embedding: {e}", logfile_handle)
            return 0
                
        # Connexion base de donnÃ©es
        try:
            client = get_qdrant_client(client_host, logfile=logfile_handle)
            create_collection(client=client, collection_name=collection_name, 
                            embedding_function=embedding_function, logfile=logfile_handle)
            disable_indexing(client=client, collection_name=collection_name, logfile=logfile_handle)
            log_and_print(f"âœ“ Collection '{collection_name}' configurÃ©e", logfile_handle)
        except Exception as e:
            log_and_print(f"âœ— Erreur configuration DB: {e}", logfile_handle)
            return 0
        
        # Traitement des fichiers
        success_count = 0
        error_count = 0
        
        try:
            for i, file_path in enumerate(pdf_documents, 1):
                file_name = os.path.splitext(os.path.basename(file_path))[0]
                
                log_and_print(f"\n{'='*60}", logfile_handle)
                log_and_print(f"TRAITEMENT {i}/{len(pdf_documents)}: {file_name}", logfile_handle)
                log_and_print(f"{'='*60}", logfile_handle)
                
                # Extraction des mÃ©tadonnÃ©es avec l'extracteur expert adaptÃ©
                metadata = extract_bocc_no_direct_metadata_expert(file_name)
                
                # Log des mÃ©tadonnÃ©es extraites
                log_and_print(f"ğŸ“Š MÃ©tadonnÃ©es extraites:", logfile_handle)
                for key, value in metadata.items():
                    if value:
                        log_and_print(f"  â€¢ {key}: {value}", logfile_handle)
                
                # Validation spÃ©cifique
                if not metadata["bulletin_number"] and not metadata["bulletin_date"]:
                    log_and_print(f"âš ï¸  Aucune mÃ©tadonnÃ©e critique extraite pour {file_name}", logfile_handle)
                    log_and_print(f"    Fichier traitÃ© comme bulletin gÃ©nÃ©rique", logfile_handle)
                
                # Traitement du fichier avec mÃ©tadonnÃ©es
                try:
                    result = chunk_and_insert_pdf_file(
                        client=client,
                        collection=collection_name,
                        embedding_function=embedding_function,
                        file_path=file_path,
                        extra_metadata=metadata,  # ğŸ”¥ FIX CRITIQUE: Passage des mÃ©tadonnÃ©es
                        separators=separators,
                        chunk_size=chunk_size,
                        chunk_overlap=chunk_overlap
                    )
                    
                    if result:
                        success_count += 1
                        log_and_print(f"âœ… {file_name} traitÃ© avec succÃ¨s", logfile_handle)
                    else:
                        error_count += 1
                        log_and_print(f"âŒ Ã‰chec traitement {file_name}", logfile_handle)
                        
                except Exception as e:
                    error_count += 1
                    log_and_print(f"âŒ Erreur traitement {file_name}: {e}", logfile_handle)
            
            # RÃ©activation de l'indexation
            reactivate_indexing(client=client, collection_name=collection_name, logfile=logfile_handle)
            
            # Rapport final
            log_and_print(f"\n{'='*60}", logfile_handle)
            log_and_print(f"RAPPORT FINAL", logfile_handle)
            log_and_print(f"{'='*60}", logfile_handle)
            log_and_print(f"âœ… Fichiers traitÃ©s avec succÃ¨s: {success_count}", logfile_handle)
            log_and_print(f"âŒ Fichiers en erreur: {error_count}", logfile_handle)
            log_and_print(f"ğŸ“Š Taux de succÃ¨s: {success_count/(success_count+error_count)*100:.1f}%", logfile_handle)
            
            return 1 if success_count > 0 else 0
            
        except Exception as e:
            log_and_print(f"âŒ Erreur critique durant le traitement: {e}", logfile_handle)
            return 0

# ==============================================================================================================

if __name__ == "__main__":
    result = ingest_no_direct_pdf_bocc()
    if result:
        print("ğŸ‰ Ingestion BOCC sans lien direct terminÃ©e avec succÃ¨s!")
    else:
        print("ğŸ’¥ Ã‰chec de l'ingestion BOCC sans lien direct")
