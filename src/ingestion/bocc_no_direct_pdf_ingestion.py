import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))
from src.utils import load_pdf_files, chunk_and_insert_pdf_file, log_and_print, get_juridical_separators

from chromadb.utils import embedding_functions as ef
from dotenv import load_dotenv
from src.db.connection import get_qdrant_client, create_collection_qdrant, disable_indexing, reactivate_indexing
from datetime import datetime
import re
from typing import Dict, Optional, List
from src.utils import get_embedding_function_with_fallback


# ==============================================================================================================

os.environ["CHROMA_ENABLE_TELEMETRY"] = "False"
load_dotenv()

client_host = os.getenv("QDRANT_HOST", "http://localhost:6333")
embedding_model = os.getenv("OLLAMA_EMBEDDING_MODEL", "paraphrase-multilingual:278m-mpnet-base-v2-fp16")
files_path = os.path.join("data/BOCC_no_pdf_direct_link/")

# ==============================================================================================================

def extract_bocc_no_direct_metadata_expert(file_name: str) -> Dict[str, Optional[str]]:
    """
    Extracteur expert de m√©tadonn√©es pour les bulletins officiels BOCC sans lien direct
    Patterns adapt√©s pour ce type de fichier sp√©cifique
    """
    metadata = {
        "bulletin_number": None,
        "bulletin_date": None,
        "bulletin_year": None,
        "bulletin_type": "BOCC_no_direct_pdf",
        "source_type": "bulletin_scraped"
    }
    
    # Patterns sp√©cifiques pour les fichiers sans lien direct
    # Ces fichiers peuvent avoir des noms diff√©rents apr√®s scraping
    bulletin_patterns = [
        r'n¬∞\s*(\d{4}[_\-]\d+)',  # Format standard
        r'bulletin[_\-](\d{4})[_\-](\d+)',  # Format alternatif
        r'bocc[_\-](\d{4})[_\-](\d+)',  # Format BOCC
        r'(\d{4})[_\-](\d{1,3})',  # Format simplifi√© ann√©e-num√©ro
        r'num[e√©]ro[_\s]*(\d{4}[_\-]\d+)'  # Variations "num√©ro"
    ]
    
    # Patterns pour dates avec plus de variabilit√©
    date_patterns = [
        r'du\s*(\d{1,2})[_\-](\d{1,2})[_\-](\d{4})',  # Format: du 15_01_2024
        r'date[_\-](\d{1,2})[_\-](\d{1,2})[_\-](\d{4})',  # Format: date_15_01_2024
        r'(\d{1,2})[_\-](\d{1,2})[_\-](\d{4})',  # Format: 15_01_2024
        r'(\d{4})[_\-](\d{1,2})[_\-](\d{1,2})',  # Format: 2024_01_15
        r'(\d{8})',  # Format: 20240115
    ]
    
    # Extraction du num√©ro de bulletin
    for pattern in bulletin_patterns:
        match = re.search(pattern, file_name, re.IGNORECASE)
        if match:
            if len(match.groups()) == 1:
                bulletin_number = match.group(1)
            else:
                # Cas o√π on a ann√©e et num√©ro s√©par√©s
                bulletin_number = f"{match.group(1)}_{match.group(2)}"
            
            metadata["bulletin_number"] = bulletin_number
            
            # Extraire l'ann√©e
            year_match = re.search(r'(\d{4})', bulletin_number)
            if year_match:
                metadata["bulletin_year"] = year_match.group(1)
            break
    
    # Extraction de la date avec gestion des formats multiples
    for pattern in date_patterns:
        match = re.search(pattern, file_name, re.IGNORECASE)
        if match:
            try:
                if len(match.groups()) == 1:
                    # Format YYYYMMDD
                    date_str = match.group(1)
                    if len(date_str) == 8:
                        parsed_date = datetime.strptime(date_str, "%Y%m%d")
                        metadata["bulletin_date"] = parsed_date
                        metadata["bulletin_year"] = str(parsed_date.year)
                        break
                        
                elif len(match.groups()) == 3:
                    # Format avec jour, mois, ann√©e
                    day, month, year = match.groups()
                    
                    # Essayer diff√©rents ordres
                    date_combinations = [
                        (day, month, year),     # DD/MM/YYYY
                        (year, month, day),     # YYYY/MM/DD
                        (month, day, year),     # MM/DD/YYYY
                    ]
                    
                    for d, m, y in date_combinations:
                        try:
                            parsed_date = datetime(int(y), int(m), int(d))
                            metadata["bulletin_date"] = parsed_date
                            metadata["bulletin_year"] = str(parsed_date.year)
                            break
                        except ValueError:
                            continue
                    
                    if metadata["bulletin_date"]:
                        break
                        
            except Exception as e:
                print(f"Erreur parsing date dans {file_name}: {e}")
                continue
    
    return metadata

def get_bocc_no_direct_separators() -> List[str]:
    """
    Separators optimis√©s pour les bulletins BOCC sans lien direct
    Ces fichiers peuvent avoir une structure l√©g√®rement diff√©rente
    """
    base_separators = get_juridical_separators()
    
    # Separators sp√©cifiques aux bulletins scrap√©s
    bocc_no_direct_separators = [
        # Structures typiques apr√®s scraping
        "\n\nTexte n¬∞ ",
        "\n\nTexte num√©ro ",
        "\n\nDocument n¬∞ ",
        "\n\nDocument num√©ro ",
        
        # Structures administratives
        "\n\nARR√äT√â du ",
        "\n\nARR√äT√â DU ",
        "\n\nD√âCRET n¬∞ ",
        "\n\nD√âCRET N¬∞ ",
        "\n\nCIRCULAIRE ",
        "\n\nINSTRUCTION ",
        "\n\nAVIS ",
        "\n\nD√âCISION ",
        "\n\nCOMMUNICATION ",
        
        # Structures d'extension
        "\n\nEXTENSION d'accord ",
        "\n\nEXTENSION de la convention ",
        "\n\nELARGISSEMENT ",
        "\n\nAGR√âMENT ",
        "\n\nD√âNONCIATION ",
        
        # Marqueurs de d√©but/fin typiques
        "\n\nMinist√®re ",
        "\n\nDirection ",
        "\n\nService ",
        "\n\nBureau ",
        
        # Separators de contenu
        "\n\nVu ",
        "\n\nConsid√©rant ",
        "\n\nArr√™te ",
        "\n\nD√©cide ",
        
    ] + base_separators
    
    return bocc_no_direct_separators

def validate_bocc_no_direct_content(text: str) -> bool:
    """
    Validation simplifi√©e du contenu BOCC - Filtre seulement le bruit √©vident
    """
    if not text or len(text.strip()) < 40:
        return False
    
    # Filtre seulement le bruit √©vident
    noise_indicators = [
        r'^\s*\d+\s*$',  # Pages contenant seulement un num√©ro
        r'^\s*sommaire\s*$',  # Pages sommaire
        r'^\s*index\s*$',  # Pages index
        r'^\s*page\s*\d+\s*$',  # Page X
        r'^\s*imprimer\s*$',  # Bouton imprimer
        r'^\s*t[e√©]l[e√©]charger\s*$',  # Bouton t√©l√©charger
    ]
    
    text_lower = text.lower().strip()
    for noise in noise_indicators:
        if re.match(noise, text_lower):
            return False
    
    return True  # ‚úÖ Accepte tout le reste


def preprocess_bocc_no_direct_text(text: str) -> str:
    """
    Preprocessing sp√©cifique pour les bulletins sans lien direct
    """
    if not text:
        return ""
    
    # Nettoyage de base
    from src.utils import clean_juridical_text
    text = clean_juridical_text(text)
    
    # Corrections sp√©cifiques aux bulletins scrap√©s
    
    # Nettoyer les artefacts de scraping
    text = re.sub(r'(?i)page\s+\d+\s+sur\s+\d+', '', text)
    text = re.sub(r'(?i)imprimer\s+cette\s+page', '', text)
    text = re.sub(r'(?i)retour\s+au\s+sommaire', '', text)
    text = re.sub(r'(?i)t[e√©]l[e√©]charger\s+le\s+pdf', '', text)
    
    # Standardiser les r√©f√©rences administratives
    text = re.sub(r"(?i)minist[e√®]re\s+du\s+travail,?\s+de\s+l['‚Äô]?emploi", 
              "Minist√®re du Travail, de l'Emploi", text)    
    
    # Standardiser les r√©f√©rences de direction
    text = re.sub(r'(?i)direction\s+g[e√©]n[e√©]rale\s+du\s+travail', 
                  'Direction g√©n√©rale du travail', text)
    
    # Standardiser les structures d'arr√™t√©
    text = re.sub(r'(?i)arr[e√™]t[e√©]\s+du\s+(\d{1,2})\s+(\w+)\s+(\d{4})', 
                  r'Arr√™t√© du \1 \2 \3', text)
    
    # Standardiser les r√©f√©rences aux textes
    text = re.sub(r'(?i)vu\s+le\s+code\s+du\s+travail', 'Vu le Code du travail', text)
    text = re.sub(r'(?i)vu\s+la\s+loi\s+n¬∞\s*([0-9\-]+)', r'Vu la loi n¬∞ \1', text)
    
    # Corriger les num√©rotations
    text = re.sub(r'(?i)article\s+([A-Z]?\d+(?:[.\-]\d+)*)', r'Article \1', text)
    
    return text

def ingest_no_direct_pdf_bocc(pdf_path: str = files_path, client_host: str = client_host) -> int:
    """
    Ingestion expert des bulletins officiels BOCC sans lien direct PDF
    """
    collection_name = "bocc"
    separators = get_bocc_no_direct_separators()
    
    # Configuration chunks adapt√©e pour les bulletins scrap√©s
    chunk_size = 1200  # L√©g√®rement plus petit pour les textes scrap√©s
    chunk_overlap = 300  # Plus de chevauchement pour compenser la fragmentation
    
    logs_dir = "logs/bocc_logs/no_direct_pdf/"
    os.makedirs(logs_dir, exist_ok=True)
    now_str = datetime.now().strftime("%d-%m-%Y_%H-%M")
    logfile_path = f"{logs_dir}log_{now_str}.log"
    
    with open(logfile_path, "w", encoding="utf-8") as logfile_handle:
        log_and_print("=" * 80, logfile_handle)
        log_and_print("INGESTION EXPERT BOCC - SANS LIEN DIRECT PDF", logfile_handle)
        log_and_print("=" * 80, logfile_handle)
        
        # Chargement des fichiers PDF
        try:
            pdf_documents = load_pdf_files(pdf_path)
            if pdf_documents:
                log_and_print(f"‚úì {len(pdf_documents)} fichiers PDF charg√©s avec succ√®s", logfile_handle)
            else:
                log_and_print(f"‚úó Aucun fichier PDF trouv√© dans {pdf_path}", logfile_handle)
                return 0
        except Exception as e:
            log_and_print(f"‚úó Erreur chargement fichiers: {e}", logfile_handle)
            return 0
        
        # Configuration embedding
        try:
            embedding_function, active_model = get_embedding_function_with_fallback(logfile_handle)
            log_and_print(f"‚úì Mod√®le embedding actif: {active_model}", logfile_handle)
        except Exception as e:
            log_and_print(f"‚úó Impossible de charger les mod√®les d'embedding: {e}", logfile_handle)
            return 0
                
        # Connexion base de donn√©es
        try:
            client = get_qdrant_client(client_host, logfile=logfile_handle)
            create_collection_qdrant(client=client, collection_name=collection_name, 
                            embedding_function=embedding_function, logfile=logfile_handle)
            disable_indexing(client=client, collection_name=collection_name, logfile=logfile_handle)
            log_and_print(f"‚úì Collection '{collection_name}' configur√©e", logfile_handle)
        except Exception as e:
            log_and_print(f"‚úó Erreur configuration DB: {e}", logfile_handle)
            return 0
        
        # Traitement des fichiers
        success_count = 0
        error_count = 0
        
        try:
            for i, file_path in enumerate(pdf_documents, 1):
                file_name = os.path.splitext(os.path.basename(file_path))[0]
                
                log_and_print(f"\n{'='*60}", logfile_handle)
                log_and_print(f"TRAITEMENT {i}/{len(pdf_documents)}: {file_name}", logfile_handle)
                log_and_print(f"{'='*60}", logfile_handle)
                
                # Extraction des m√©tadonn√©es avec l'extracteur expert adapt√©
                metadata = extract_bocc_no_direct_metadata_expert(file_name)
                
                # Log des m√©tadonn√©es extraites
                log_and_print(f"üìä M√©tadonn√©es extraites:", logfile_handle)
                for key, value in metadata.items():
                    if value:
                        log_and_print(f"  ‚Ä¢ {key}: {value}", logfile_handle)
                
                # Validation sp√©cifique
                if not metadata["bulletin_number"] and not metadata["bulletin_date"]:
                    log_and_print(f"‚ö†Ô∏è  Aucune m√©tadonn√©e critique extraite pour {file_name}", logfile_handle)
                    log_and_print(f"    Fichier trait√© comme bulletin g√©n√©rique", logfile_handle)
                
                # Traitement du fichier avec m√©tadonn√©es
                try:
                    result = chunk_and_insert_pdf_file(
                        client=client,
                        collection=collection_name,
                        embedding_function=embedding_function,
                        file_path=file_path,
                        extra_metadata=metadata,  # üî• FIX CRITIQUE: Passage des m√©tadonn√©es
                        separators=separators,
                        chunk_size=chunk_size,
                        chunk_overlap=chunk_overlap
                    )
                    
                    if result:
                        success_count += 1
                        log_and_print(f"‚úÖ {file_name} trait√© avec succ√®s", logfile_handle)
                    else:
                        error_count += 1
                        log_and_print(f"‚ùå √âchec traitement {file_name}", logfile_handle)
                        
                except Exception as e:
                    error_count += 1
                    log_and_print(f"‚ùå Erreur traitement {file_name}: {e}", logfile_handle)
            
            # R√©activation de l'indexation
            reactivate_indexing(client=client, collection_name=collection_name, logfile=logfile_handle)
            
            # Rapport final
            log_and_print(f"\n{'='*60}", logfile_handle)
            log_and_print(f"RAPPORT FINAL", logfile_handle)
            log_and_print(f"{'='*60}", logfile_handle)
            log_and_print(f"‚úÖ Fichiers trait√©s avec succ√®s: {success_count}", logfile_handle)
            log_and_print(f"‚ùå Fichiers en erreur: {error_count}", logfile_handle)
            log_and_print(f"üìä Taux de succ√®s: {success_count/(success_count+error_count)*100:.1f}%", logfile_handle)
            
            if success_count > 0:
                # Compter le total de chunks r√©ellement ins√©r√©s
                try:
                    collection_info = client.get_collection(collection_name)
                    total_chunks = getattr(collection_info, 'points_count', 0)
                    log_and_print(f"üìä Total chunks dans la collection: {total_chunks}", logfile_handle)
                    return total_chunks
                except:
                    return success_count
            else:
                return 0
            
        except Exception as e:
            log_and_print(f"‚ùå Erreur critique durant le traitement: {e}", logfile_handle)
            return 0

# ==============================================================================================================

if __name__ == "__main__":
    result = ingest_no_direct_pdf_bocc()
    if result:
        print("üéâ Ingestion BOCC sans lien direct termin√©e avec succ√®s!")
    else:
        print("üí• √âchec de l'ingestion BOCC sans lien direct")
